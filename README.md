# 최저가 알림이 (Price Alert)

다나와/지마켓에서 원하는 상품의 최저가를 추적하고 이메일로 알림을 받는 데스크톱 프로그램입니다.

## 주요 기능

- **2-step 등록**: 키워드로 검색 → 후보 선택 → 추적 시작 (오타/오매칭 방지)
- **주기적 가격 조회**: 최소 15분 간격으로 크롤링 (사이트 차단 방지)
- **이메일 알림**: 설정된 주기마다 최저가 요약 발송
- **이상징후 감지**: 가격 급변, 상품명 변경, 차단 의심 시 알림

## 설치 및 실행

### 1. 환경 설정

```bash
# 가상환경 생성 및 활성화
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 패키지 설치
pip install -r requirements.txt
```

### 2. 이메일 설정 준비

**Gmail 사용 시:**
1. Google 계정 → 보안 → 2단계 인증 활성화
2. 같은 보안 영역에서 ‘앱 비밀번호’(App passwords) 메뉴로 이동
   * 메뉴가 안 보이면 상단 검색창에 “앱 비밀번호”라고 검색
3. 생성된 16자리 비밀번호 저장

**Naver 사용 시:**
1. 네이버 메일 → 환경설정 → POP3/IMAP 설정
2. SMTP 사용 설정 활성화

### 3. 프로그램 실행

```bash
python main.py
```

## 사용 방법

### 기본 사용 흐름

1. **키워드 입력**: 추적할 상품 키워드 입력 (예: "RTX 4070 Ti SUPER")
2. **설정 선택**:
   - 사이트: 다나와 / 지마켓 / 둘 다
   - 크롤링 주기: 최소 15분 (권장 30분)
   - 알림 주기: 최소 1시간 (권장 24시간)
   - 수신 이메일: 로컬파트 + 도메인 선택
3. **검색/후보 가져오기**: 키워드로 검색 실행
4. **후보 선택**: 검색 결과 중 원하는 상품 1개 선택
5. **추적 시작**: 발신자 이메일 정보 입력 후 추적 시작
6. **알림 수신**: 설정된 주기마다 최저가 이메일 수신

### 테스트 알림

실제 추적 시작 전에 이메일 설정이 정상인지 확인할 수 있습니다.
- 수신 이메일 입력 → "테스트 알림" 버튼 클릭

## 주의사항

### 크롤링 주기 제한
- **최소 15분**: 사이트가 프로그램을 악성봇으로 오인하는 것을 방지
- 짧은 주기 사용 시 차단 가능성 증가
- 권장: 30분 ~ 1시간

### 스크래퍼 업데이트 필요
현재 코드의 `scrapers/gmarket.py`는 **스켈레톤**입니다.
실제 사용하려면:
1. 지마켓 검색 결과 페이지 HTML 구조 분석
2. CSS 셀렉터를 실제 값으로 교체
3. 상품 페이지 가격 추출 로직 구현

### 이메일 발송 한도
- Gmail: 일일 약 500통 제한
- Naver: SMTP 사용량 제한
- 알림 주기를 너무 짧게 설정하지 마세요

### 데이터 저장 정책
- 가격 히스토리를 장기 저장하지 않습니다
- `data/state.json`에 최소 상태만 저장
- 알림/운영을 위한 최소 정보만 유지

## 파일 구조

```
price-alert/
├── main.py                 # 프로그램 엔트리
├── config/
│   └── constants.py        # 전역 상수
├── ui/
│   ├── app.py             # Tkinter 메인 UI
│   └── widgets.py         # 공통 위젯
├── core/
│   ├── scheduler.py       # 주기 실행기
│   ├── models.py          # 데이터 모델
│   ├── normalizer.py      # 정규화/검증
│   └── state_store.py     # 상태 저장
├── scrapers/
│   ├── base.py            # 스크래퍼 인터페이스
│   ├── danawa.py          # 다나와 스크래퍼
│   └── gmarket.py         # 지마켓 스크래퍼
├── notify/
│   ├── emailer.py         # 이메일 발송
│   └── templates.py       # 이메일 템플릿
├── data/
│   └── state.json         # 최소 상태 저장
└── logs/
    └── app.log            # 실행 로그
```

## 트러블슈팅

### 검색 결과가 없어요
- 키워드를 단순화하세요 (브랜드명, 모델명만)
- 띄어쓰기를 변경해보세요
- 필요시 URL 직접 입력 모드 사용 (향후 구현)

### 이메일이 안 가요
- 앱 비밀번호를 올바르게 입력했는지 확인
- 발신자 이메일의 SMTP 설정 확인
- "테스트 알림" 기능으로 먼저 확인

### 차단 의심 메시지가 떠요
- 크롤링 주기를 더 길게 설정 (1시간 이상)
- 프로그램을 잠시 중지하고 시간을 두고 재시작

## 개발 가이드

### 스크래퍼 구현하기

1. **검색 결과 페이지 분석**:
   - 브라우저 개발자 도구로 HTML 구조 확인
   - 상품명, 가격, 링크 요소의 CSS 셀렉터 파악

2. **`search()` 메서드 구현**:
   ```python
   # 실제 셀렉터로 교체
   items = soup.select('.actual-product-selector')
   title = item.select_one('.actual-title-selector').get_text()
   ```

3. **`fetch()` 메서드 구현**:
   ```python
   # 상품 페이지 가격 셀렉터
   price_elem = soup.select_one('.actual-price-selector')
   ```

4. **테스트**:
   ```bash
   python -c "from scrapers.danawa import DanawaScraper; \
              s = DanawaScraper(); \
              print(s.search('RTX 4070'))"
   ```

## 라이선스

이 프로그램은 개인 사용 목적으로 제작되었습니다.
크롤링 대상 사이트의 이용약관을 준수하여 사용하세요.

## 기여

버그 리포트나 기능 제안은 이슈로 등록해주세요.